"""
PaperGen_Pro - é¡µé¢è§†å›¾ (V2)

5 æ­¥é¡µé¢æµï¼š
  Step 0: ä¸Šä¼  PDF (æ”¯æŒå¤šæ–‡ä»¶) + è¾“å…¥å†™ä½œæ–¹å‘ -> Phase 1
  Step 1: å¤§çº²å®¡é˜… (åªè¯»é¢„è§ˆ + AI å®¡é˜…æ„è§)
  Step 2: å¤§çº²ç¼–è¾‘å™¨ (ç”¨æˆ·ä¿®æ”¹ JSON å¤§çº²)
  Step 3: å†™ä½œè¿›åº¦ (Phase 2 åˆ†ç« èŠ‚ç”Ÿæˆ)
  Step 4: æœ€ç»ˆç»“æœ (æŸ¥çœ‹æ­£æ–‡ + ä¸‹è½½ Word)

UI å±‚åªè´Ÿè´£å±•ç¤ºå’ŒçŠ¶æ€æµè½¬ï¼Œä¸å¤„ç† AI è°ƒç”¨ã€‚
"""
import json
import os

import streamlit as st

from backend.workflows import outline_graph, writing_graph


# =====================================================================
# Step 0: ä¸Šä¼  PDF ä¸è®¾å®šæ–¹å‘
# =====================================================================

def view_upload():
    """ä¸Šä¼  PDF æ–‡ä»¶ (æ”¯æŒ 1-5 ä¸ª) å¹¶é…ç½®è®ºæ–‡å‚æ•°ï¼Œè§¦å‘ Phase 1ã€‚"""

    st.header("ğŸ“„ ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ è®ºæ–‡ç´ æ")
    st.markdown(
        "é…ç½®è®ºæ–‡å‚æ•°ï¼Œä¸Šä¼ å‚è€ƒè®ºæ–‡ PDFï¼Œå¹¶æè¿°æ‚¨çš„å†™ä½œæ–¹å‘ï¼Œ"
        "AI å°†è‡ªåŠ¨è§£æå†…å®¹å¹¶ç”Ÿæˆè®ºæ–‡å¤§çº²ã€‚"
    )

    # =====================================================================
    # ç§‘ç›®ä¸é¢˜ç›®
    # =====================================================================
    st.subheader("ğŸ“š ç§‘ç›®ä¸é¢˜ç›®")
    st.caption("â„¹ï¸ ä¸çŸ¥é“æ€ä¹ˆé€‰é¢˜ï¼Ÿåªéœ€è¦è¾“å…¥è¦æ±‚ï¼Œç‚¹å‡»AIæ¨èé¢˜ç›®ï¼")

    subject_list = [
        "è®¡ç®—æœºç§‘å­¦", "ç”µå­ä¿¡æ¯", "äººå·¥æ™ºèƒ½", "è½¯ä»¶å·¥ç¨‹", "é€šä¿¡å·¥ç¨‹",
        "æœºæ¢°å·¥ç¨‹", "ç”µæ°”å·¥ç¨‹", "åœŸæœ¨å·¥ç¨‹", "åŒ–å­¦å·¥ç¨‹", "ææ–™ç§‘å­¦",
        "ç»æµå­¦", "ç®¡ç†å­¦", "é‡‘èå­¦", "ä¼šè®¡å­¦", "å¸‚åœºè¥é”€",
        "æ³•å­¦", "æ•™è‚²å­¦", "å¿ƒç†å­¦", "æ–‡å­¦", "å†å²å­¦",
        "å“²å­¦", "ç¤¾ä¼šå­¦", "æ”¿æ²»å­¦", "æ–°é—»ä¼ æ’­", "è‰ºæœ¯è®¾è®¡",
        "åŒ»å­¦", "æŠ¤ç†å­¦", "è¯å­¦", "ç”Ÿç‰©ç§‘å­¦", "ç¯å¢ƒç§‘å­¦",
        "æ•°å­¦", "ç‰©ç†å­¦", "åŒ–å­¦", "å†œå­¦", "å…¶ä»–",
    ]

    col_subject, col_title, col_ai_btn = st.columns([1.5, 3, 1])

    with col_subject:
        paper_subject = st.selectbox(
            "ç§‘ç›®",
            options=subject_list,
            index=subject_list.index(
                st.session_state.get("paper_subject", "è®¡ç®—æœºç§‘å­¦")
            ),
            key="select_paper_subject",
        )
        st.session_state["paper_subject"] = paper_subject

    with col_title:
        # å¤„ç† AI æ¨èé¢˜ç›®çš„å¾…å›å¡«å€¼ï¼ˆå¿…é¡»åœ¨ widget å®ä¾‹åŒ–ä¹‹å‰è®¾ç½®ï¼‰
        if "_pending_title" in st.session_state:
            st.session_state["input_paper_title"] = st.session_state.pop("_pending_title")

        paper_title = st.text_input(
            "è®ºæ–‡é¢˜ç›®",
            value=st.session_state.get("paper_title", ""),
            placeholder="è¯·è¾“å…¥ 5-50 å­—è®ºæ–‡é¢˜ç›®ï¼Œæˆ–è¾“å…¥å…³é”®è¯ä½¿ç”¨ AI åªèƒ½é€‰é¢˜ï¼",
            key="input_paper_title",
        )
        st.session_state["paper_title"] = paper_title

    with col_ai_btn:
        st.markdown("<br>", unsafe_allow_html=True)
        ai_title_btn = st.button("ğŸ¤– AIæ¨èé¢˜ç›®", type="primary", key="btn_ai_title")

    # AI æ¨èé¢˜ç›®é€»è¾‘
    if ai_title_btn:
        user_hint = paper_title.strip() or st.session_state.get("user_intent", "")
        if not user_hint:
            st.warning("âš ï¸ è¯·å…ˆè¾“å…¥ä¸€äº›å…³é”®è¯æˆ–å†™ä½œæ–¹å‘ï¼Œä»¥ä¾¿ AI æ¨èé¢˜ç›®ã€‚")
        else:
            try:
                with st.spinner("ğŸ¤– AI æ­£åœ¨ä¸ºæ‚¨æ¨èé¢˜ç›®..."):
                    from backend.services import call_deepseek_recommend_title
                    titles = call_deepseek_recommend_title(
                        subject=paper_subject,
                        user_intent=user_hint,
                    )
                if titles:
                    st.session_state["_recommended_titles"] = titles
                else:
                    st.warning("âš ï¸ AI æœªèƒ½ç”Ÿæˆæ¨èé¢˜ç›®ï¼Œè¯·å°è¯•ä¿®æ”¹å…³é”®è¯åé‡è¯•ã€‚")
            except Exception as e:
                st.error(f"âŒ AI æ¨èé¢˜ç›®å¤±è´¥: {e}")

    # æ˜¾ç¤ºæ¨èçš„é¢˜ç›®
    recommended_titles = st.session_state.get("_recommended_titles", [])
    if recommended_titles:
        st.markdown("**ğŸ¯ AI æ¨èé¢˜ç›®** ï¼ˆç‚¹å‡»é€‰æ‹©ï¼‰ï¼š")
        cols = st.columns(len(recommended_titles))
        for idx, title in enumerate(recommended_titles):
            with cols[idx]:
                if st.button(
                    title,
                    key=f"rec_title_{idx}",
                    use_container_width=True,
                ):
                    st.session_state["paper_title"] = title
                    st.session_state["_pending_title"] = title
                    st.session_state["_recommended_titles"] = []
                    st.rerun()

    st.divider()

    # =====================================================================
    # è®ºæ–‡è¯­è¨€ / å­¦ä¸šç±»å‹ / è®ºæ–‡æ°´å¹³
    # =====================================================================
    col_lang, col_academic, col_level = st.columns(3)

    with col_lang:
        st.subheader("ğŸŒ è®ºæ–‡è¯­è¨€")
        paper_language = st.selectbox(
            "è¯­è¨€",
            options=["ä¸­æ–‡", "è‹±æ–‡"],
            index=["ä¸­æ–‡", "è‹±æ–‡"].index(
                st.session_state.get("paper_language", "ä¸­æ–‡")
            ),
            key="select_paper_language",
            label_visibility="collapsed",
        )
        st.session_state["paper_language"] = paper_language

    with col_academic:
        st.subheader("ğŸ“ å­¦ä¸šç±»å‹")
        academic_options = ["ä¸“ç§‘", "æœ¬ç§‘", "ç ”ç©¶ç”Ÿ"]
        academic_type = st.radio(
            "å­¦ä¸šç±»å‹",
            options=academic_options,
            index=academic_options.index(
                st.session_state.get("academic_type", "æœ¬ç§‘")
            ),
            horizontal=True,
            key="radio_academic_type",
            label_visibility="collapsed",
        )
        st.session_state["academic_type"] = academic_type

    with col_level:
        st.subheader("ğŸ“Š è®ºæ–‡æ°´å¹³")
        level_options = ["åˆçº§", "é«˜çº§"]
        paper_level = st.radio(
            "è®ºæ–‡æ°´å¹³",
            options=level_options,
            index=level_options.index(
                st.session_state.get("paper_level", "åˆçº§")
            ),
            horizontal=True,
            key="radio_paper_level",
            label_visibility="collapsed",
        )
        st.session_state["paper_level"] = paper_level

    st.divider()

    # =====================================================================
    # è®ºæ–‡ç±»å‹
    # =====================================================================
    st.subheader("ğŸ“‹ è®ºæ–‡ç±»å‹")
    paper_type_options = ["æ¯•ä¸šè®ºæ–‡", "ç»“è¯¾è®ºæ–‡", "å¼€é¢˜æŠ¥å‘Š", "ä»»åŠ¡ä¹¦", "æ–‡çŒ®ç»¼è¿°"]
    paper_type = st.radio(
        "è®ºæ–‡ç±»å‹",
        options=paper_type_options,
        index=paper_type_options.index(
            st.session_state.get("paper_type", "æ¯•ä¸šè®ºæ–‡")
        ),
        horizontal=True,
        key="radio_paper_type",
        label_visibility="collapsed",
    )
    st.session_state["paper_type"] = paper_type

    st.divider()

    # =====================================================================
    # è®ºæ–‡å­—æ•°
    # =====================================================================
    st.subheader("ğŸ“ è®ºæ–‡å­—æ•°")
    st.caption("å­—æ•°ä¾›å‚è€ƒï¼Œå¯èƒ½å­˜åœ¨è¯¯å·®ï¼Œå±äºæ­£å¸¸æƒ…å†µã€‚")
    target_word_count = st.slider(
        "ç›®æ ‡å­—æ•°",
        min_value=3000,
        max_value=25000,
        value=st.session_state.get("target_word_count", 8000),
        step=1000,
        format="%d",
        key="slider_word_count",
        label_visibility="collapsed",
    )
    st.session_state["target_word_count"] = target_word_count

    # å­—æ•°åˆ»åº¦è¯´æ˜
    marks_cols = st.columns(9)
    mark_labels = ["3000", "5000", "8000", "10000", "12000",
                   "15000", "18000", "20000", "25000"]
    for i, label in enumerate(mark_labels):
        with marks_cols[i]:
            val = int(label)
            if val > 15000:
                st.markdown(
                    f"<span style='color: #e74c3c; font-size: 12px;'>"
                    f"{label}</span>",
                    unsafe_allow_html=True,
                )
            else:
                st.markdown(
                    f"<span style='font-size: 12px;'>{label}</span>",
                    unsafe_allow_html=True,
                )

    st.divider()

    # =====================================================================
    # PDF ä¸Šä¼ 
    # =====================================================================
    st.subheader("ğŸ“ ä¸Šä¼ å‚è€ƒè®ºæ–‡ PDF")
    uploaded_files = st.file_uploader(
        "ä¸Šä¼  PDF æ–‡ä»¶ï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
        type=["pdf"],
        accept_multiple_files=True,
        help="æ”¯æŒæœ€å¤§ 50MB çš„ PDF æ–‡ä»¶ï¼Œæœ€å¤šåŒæ—¶ä¸Šä¼  5 ä¸ª",
    )

    if uploaded_files and len(uploaded_files) > 5:
        st.warning("âš ï¸ æœ€å¤šæ”¯æŒ 5 ä¸ªæ–‡ä»¶ï¼Œè¯·å‡å°‘æ–‡ä»¶æ•°é‡ã€‚")
        uploaded_files = uploaded_files[:5]

    if uploaded_files:
        st.success(f"âœ… å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼š")
        for f in uploaded_files:
            size_mb = len(f.getvalue()) / (1024 * 1024)
            st.caption(f"  ğŸ“ {f.name} ({size_mb:.1f} MB)")

    # =====================================================================
    # å†™ä½œæ–¹å‘è¾“å…¥
    # =====================================================================
    user_intent = st.text_area(
        "âœï¸ è¯·æè¿°æ‚¨çš„å†™ä½œæ–¹å‘",
        placeholder=(
            "ä¾‹å¦‚ï¼šæˆ‘å¸Œæœ›å›´ç»•ã€Œå¤§è¯­è¨€æ¨¡å‹åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨ã€è¿™ä¸ªä¸»é¢˜ï¼Œ"
            "é‡ç‚¹åˆ†æ GPT-4 å’Œ DeepSeek åœ¨è‡ªåŠ¨è¯„åˆ†å’Œä¸ªæ€§åŒ–è¾…å¯¼æ–¹é¢çš„è¡¨ç°..."
        ),
        height=120,
    )

    st.divider()

    # =====================================================================
    # ä¸­è‹±æ–‡å…³é”®è¯
    # =====================================================================
    st.subheader("ğŸ”‘ å…³é”®è¯")

    col_kw_cn, col_kw_en = st.columns(2)

    with col_kw_cn:
        st.markdown("**ä¸­æ–‡å…³é”®è¯** <span style='color: gray; font-size: 12px;'>"
                     "å…³é”®è¯ä¸Šé™4ä¸ªï¼Œå¯åˆ é™¤åè‡ªå®šä¹‰å…³é”®è¯</span>",
                     unsafe_allow_html=True)

        # æ˜¾ç¤ºå·²æœ‰å…³é”®è¯æ ‡ç­¾
        keywords_cn = st.session_state.get("keywords_cn", [])
        if keywords_cn:
            kw_cols = st.columns(len(keywords_cn) + 1)
            for idx, kw in enumerate(keywords_cn):
                with kw_cols[idx]:
                    if st.button(f"âŒ {kw}", key=f"del_kw_cn_{idx}"):
                        st.session_state["keywords_cn"].pop(idx)
                        st.rerun()

        # æ·»åŠ æ–°å…³é”®è¯
        cn_col_input, cn_col_btn = st.columns([3, 1])
        with cn_col_input:
            new_kw_cn = st.text_input(
                "æ·»åŠ ä¸­æ–‡å…³é”®è¯",
                placeholder="å…³é”®è¯ä¸Šé™4ä¸ªï¼Œå¯åˆ é™¤åè‡ªå®šä¹‰å…³é”®è¯",
                key="input_kw_cn",
                label_visibility="collapsed",
            )
        with cn_col_btn:
            if st.button("â• æ·»åŠ ", key="btn_add_kw_cn"):
                if new_kw_cn.strip() and len(keywords_cn) < 4:
                    st.session_state["keywords_cn"].append(new_kw_cn.strip())
                    st.rerun()
                elif len(keywords_cn) >= 4:
                    st.warning("âš ï¸ æœ€å¤š 4 ä¸ªä¸­æ–‡å…³é”®è¯")

    with col_kw_en:
        st.markdown("**è‹±æ–‡å…³é”®è¯** <span style='color: gray; font-size: 12px;'>"
                     "å…³é”®è¯ä¸Šé™4ä¸ªï¼Œå¯åˆ é™¤åè‡ªå®šä¹‰å…³é”®è¯</span>",
                     unsafe_allow_html=True)

        # æ˜¾ç¤ºå·²æœ‰å…³é”®è¯æ ‡ç­¾
        keywords_en = st.session_state.get("keywords_en", [])
        if keywords_en:
            kw_cols = st.columns(len(keywords_en) + 1)
            for idx, kw in enumerate(keywords_en):
                with kw_cols[idx]:
                    if st.button(f"âŒ {kw}", key=f"del_kw_en_{idx}"):
                        st.session_state["keywords_en"].pop(idx)
                        st.rerun()

        # æ·»åŠ æ–°å…³é”®è¯
        en_col_input, en_col_btn = st.columns([3, 1])
        with en_col_input:
            new_kw_en = st.text_input(
                "æ·»åŠ è‹±æ–‡å…³é”®è¯",
                placeholder="å…³é”®è¯ä¸Šé™4ä¸ªï¼Œå¯åˆ é™¤åè‡ªå®šä¹‰å…³é”®è¯",
                key="input_kw_en",
                label_visibility="collapsed",
            )
        with en_col_btn:
            if st.button("â• æ·»åŠ ", key="btn_add_kw_en"):
                if new_kw_en.strip() and len(keywords_en) < 4:
                    st.session_state["keywords_en"].append(new_kw_en.strip())
                    st.rerun()
                elif len(keywords_en) >= 4:
                    st.warning("âš ï¸ æœ€å¤š 4 ä¸ªè‹±æ–‡å…³é”®è¯")

    # AI è‡ªåŠ¨ç”Ÿæˆå…³é”®è¯æŒ‰é’®
    ai_kw_btn = st.button(
        "ğŸ¤– AI è‡ªåŠ¨ç”Ÿæˆå…³é”®è¯",
        key="btn_ai_keywords",
        disabled=(not st.session_state.get("paper_title", "").strip()),
    )
    if ai_kw_btn:
        try:
            with st.spinner("ğŸ¤– AI æ­£åœ¨ç”Ÿæˆå…³é”®è¯..."):
                from backend.services import call_deepseek_generate_keywords
                kw_result = call_deepseek_generate_keywords(
                    title=st.session_state.get("paper_title", ""),
                    subject=st.session_state.get("paper_subject", ""),
                    user_intent=user_intent.strip() or st.session_state.get(
                        "paper_title", ""
                    ),
                )
            if kw_result.get("cn"):
                st.session_state["keywords_cn"] = kw_result["cn"][:4]
            if kw_result.get("en"):
                st.session_state["keywords_en"] = kw_result["en"][:4]
            st.rerun()
        except Exception as e:
            st.error(f"âŒ AI ç”Ÿæˆå…³é”®è¯å¤±è´¥: {e}")

    st.divider()

    # =====================================================================
    # è§¦å‘ Phase 1
    # =====================================================================
    col1, col2 = st.columns([1, 3])
    with col1:
        run_button = st.button(
            "ğŸš€ å¼€å§‹ç”Ÿæˆ",
            type="primary",
            use_container_width=True,
            disabled=(not uploaded_files or not user_intent.strip()),
        )

    if run_button and uploaded_files:
        # è¯»å–æ‰€æœ‰æ–‡ä»¶çš„å­—èŠ‚æ•°æ®
        raw_files = []
        for f in uploaded_files:
            raw_files.append((f.read(), f.name))

        # æ„å»ºåˆå§‹çŠ¶æ€ï¼ˆåŒ…å«è®ºæ–‡é…ç½®ï¼‰
        initial_state = {
            "paper_subject": st.session_state.get("paper_subject", ""),
            "paper_title": st.session_state.get("paper_title", ""),
            "paper_language": st.session_state.get("paper_language", "ä¸­æ–‡"),
            "academic_type": st.session_state.get("academic_type", "æœ¬ç§‘"),
            "paper_level": st.session_state.get("paper_level", "åˆçº§"),
            "paper_type": st.session_state.get("paper_type", "æ¯•ä¸šè®ºæ–‡"),
            "target_word_count": st.session_state.get("target_word_count", 8000),
            "keywords_cn": st.session_state.get("keywords_cn", []),
            "keywords_en": st.session_state.get("keywords_en", []),
            "pdf_content": "",
            "is_scanned": False,
            "images_data": [],
            "user_intent": user_intent.strip(),
            "outline": {},
            "review_feedback": "",
            "sections_content": {},
            "final_doc_path": "",
            "_raw_files": raw_files,
        }

        # æ‰§è¡Œ Phase 1: è§£æ -> å¤§çº² -> å®¡é˜…
        try:
            with st.spinner("ğŸ”„ AI æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™..."):
                progress_bar = st.progress(0, text="æ­£åœ¨è§£æ PDF...")

                final_state = {}
                step_count = 0
                total_steps = 3

                for event in outline_graph.stream(initial_state):
                    step_count += 1
                    progress = min(step_count / total_steps, 1.0)

                    if "parse_pdf" in event:
                        progress_bar.progress(
                            progress,
                            text=f"âœ… PDF è§£æå®Œæˆ "
                                 f"(å›¾ç‰‡: {len(event['parse_pdf'].get('images_data', []))} å¼ )ï¼Œ"
                                 f"æ­£åœ¨ç”Ÿæˆå¤§çº²éª¨æ¶..."
                        )
                        final_state.update(event["parse_pdf"])

                    elif "generate_skeleton" in event:
                        sections_count = len(
                            event["generate_skeleton"]
                            .get("outline_skeleton", {})
                            .get("sections", [])
                        )
                        progress_bar.progress(
                            progress,
                            text=f"âœ… éª¨æ¶ç”Ÿæˆå®Œæˆ ({sections_count} ä¸ªç« èŠ‚)ï¼Œ"
                                 f"æ­£åœ¨ç”ŸæˆåŒç‰ˆæœ¬å¤§çº²..."
                        )
                        final_state.update(event["generate_skeleton"])

                    elif "generate_variants" in event:
                        progress_bar.progress(progress, text="âœ… åŒç‰ˆæœ¬å¤§çº²ç”Ÿæˆå®Œæˆï¼")
                        final_state.update(event["generate_variants"])

                progress_bar.progress(1.0, text="ğŸ‰ Phase 1 å…¨éƒ¨å®Œæˆï¼")

            # ä¿å­˜åˆ° session_state
            if final_state:
                st.session_state["pdf_content"] = final_state.get("pdf_content", "")
                st.session_state["is_scanned"] = final_state.get("is_scanned", False)
                st.session_state["images_data"] = final_state.get("images_data", [])
                st.session_state["user_intent"] = user_intent
                st.session_state["outline_skeleton"] = final_state.get(
                    "outline_skeleton", {}
                )
                st.session_state["outline_variant_a"] = final_state.get(
                    "outline_variant_a", {}
                )
                st.session_state["outline_variant_b"] = final_state.get(
                    "outline_variant_b", {}
                )
                st.session_state["cherry_picks"] = {}
                st.session_state["outline"] = {}
                st.session_state["review_feedback"] = ""
                st.session_state["phase1_completed"] = True
                st.session_state["current_step"] = 1
                st.rerun()

        except Exception as e:
            error_msg = str(e)
            if "402" in error_msg or "Insufficient Balance" in error_msg:
                st.error(
                    "âŒ **API ä½™é¢ä¸è¶³**\n\n"
                    "æ‚¨çš„ DeepSeek API è´¦æˆ·ä½™é¢ä¸è¶³ï¼Œè¯·å‰å¾€ "
                    "[DeepSeek æ§åˆ¶å°](https://platform.deepseek.com/) å……å€¼åé‡è¯•ã€‚"
                )
            elif "401" in error_msg or "Unauthorized" in error_msg:
                st.error(
                    "âŒ **API Key æ— æ•ˆ**\n\n"
                    "è¯·æ£€æŸ¥ `.env` æ–‡ä»¶ä¸­çš„ `DEEPSEEK_API_KEY` æ˜¯å¦æ­£ç¡®ã€‚"
                )
            else:
                st.error(f"âŒ **AI å¤„ç†å‡ºé”™**: {error_msg}")
            st.info("ğŸ’¡ è¯·è§£å†³ä¸Šè¿°é—®é¢˜åï¼Œé‡æ–°ç‚¹å‡»ã€Œå¼€å§‹ç”Ÿæˆã€æŒ‰é’®ã€‚")

    # =====================================================================
    # ğŸ› ï¸ å¼€å‘è°ƒè¯•é¢æ¿ï¼ˆä»…å¼€å‘é˜¶æ®µæ˜¾ç¤ºï¼Œå‘å¸ƒå‰åˆ é™¤æ­¤æ®µï¼‰
    # =====================================================================
    if st.session_state.get("debug_mode", False):
        st.divider()
        with st.expander("ğŸ› ï¸ å¼€å‘è°ƒè¯•é¢æ¿ â€” æŸ¥çœ‹é…ç½®å¦‚ä½•å½±å“ AI Prompt", expanded=True):
            # --- å½“å‰é…ç½®ä¸€è§ˆ ---
            st.markdown("### ğŸ“‹ å½“å‰è®ºæ–‡é…ç½®")
            debug_config = {
                "ç§‘ç›® (paper_subject)": st.session_state.get("paper_subject", ""),
                "é¢˜ç›® (paper_title)": st.session_state.get("paper_title", ""),
                "è¯­è¨€ (paper_language)": st.session_state.get("paper_language", "ä¸­æ–‡"),
                "å­¦ä¸šç±»å‹ (academic_type)": st.session_state.get("academic_type", "æœ¬ç§‘"),
                "è®ºæ–‡æ°´å¹³ (paper_level)": st.session_state.get("paper_level", "åˆçº§"),
                "è®ºæ–‡ç±»å‹ (paper_type)": st.session_state.get("paper_type", "æ¯•ä¸šè®ºæ–‡"),
                "ç›®æ ‡å­—æ•° (target_word_count)": st.session_state.get("target_word_count", 8000),
                "ä¸­æ–‡å…³é”®è¯ (keywords_cn)": st.session_state.get("keywords_cn", []),
                "è‹±æ–‡å…³é”®è¯ (keywords_en)": st.session_state.get("keywords_en", []),
            }
            for label, val in debug_config.items():
                st.text(f"  {label}: {val}")

            st.markdown("---")

            # --- æ¨¡æ‹Ÿ Prompt ç‰‡æ®µ ---
            st.markdown("### ğŸ§  å¤§çº²ç”Ÿæˆ Prompt ä¸­çš„é…ç½®æ®µ")
            st.markdown(
                "ä»¥ä¸‹æ˜¯ `call_deepseek_generate_outline()` å‘é€ç»™ AI çš„ "
                "**è®ºæ–‡é…ç½®ä¿¡æ¯æ®µ**ï¼ˆsystem prompt çš„è¿½åŠ éƒ¨åˆ†ï¼‰ï¼š"
            )

            _subject = st.session_state.get("paper_subject", "æœªæŒ‡å®š")
            _title = st.session_state.get("paper_title", "æœªæŒ‡å®š")
            _lang = st.session_state.get("paper_language", "ä¸­æ–‡")
            _academic = st.session_state.get("academic_type", "æœ¬ç§‘")
            _level = st.session_state.get("paper_level", "åˆçº§")
            _ptype = st.session_state.get("paper_type", "æ¯•ä¸šè®ºæ–‡")
            _wcount = st.session_state.get("target_word_count", 8000)
            _kw_cn = st.session_state.get("keywords_cn", [])
            _kw_en = st.session_state.get("keywords_en", [])

            outline_prompt_segment = (
                f"è®ºæ–‡é…ç½®ä¿¡æ¯ï¼š\n"
                f"- ç§‘ç›®: {_subject}\n"
                f"- é¢˜ç›®: {_title}\n"
                f"- è¯­è¨€: {_lang}\n"
                f"- å­¦ä¸šç±»å‹: {_academic}\n"
                f"- è®ºæ–‡æ°´å¹³: {_level}\n"
                f"- è®ºæ–‡ç±»å‹: {_ptype}\n"
                f"- ç›®æ ‡å­—æ•°: {_wcount}\n"
                f"- ä¸­æ–‡å…³é”®è¯: {', '.join(_kw_cn) if _kw_cn else '(æ— )'}\n"
                f"- è‹±æ–‡å…³é”®è¯: {', '.join(_kw_en) if _kw_en else '(æ— )'}\n"
                f"\n"
                f"è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šé…ç½®ç”Ÿæˆå¤§çº²ï¼Œç‰¹åˆ«æ³¨æ„ï¼š\n"
                f"1. ä½¿ç”¨æŒ‡å®šçš„è®ºæ–‡è¯­è¨€æ’°å†™\n"
                f"2. ç« èŠ‚æ•°é‡å’Œæ·±åº¦åº”ç¬¦åˆå­¦ä¸šç±»å‹å’Œè®ºæ–‡æ°´å¹³è¦æ±‚\n"
                f"3. ç›®æ ‡æ€»å­—æ•°çº¦ {_wcount} å­—ï¼Œåˆç†åˆ†é…å„ç« èŠ‚å­—æ•°\n"
                f"4. è®ºæ–‡ç±»å‹ä¸ºã€Œ{_ptype}ã€ï¼Œè¯·éµå¾ªå¯¹åº”çš„æ ¼å¼è§„èŒƒ"
            )
            st.code(outline_prompt_segment, language="text")

            st.markdown("---")

            # --- ç« èŠ‚å†™ä½œ Prompt ç‰‡æ®µ ---
            st.markdown("### âœï¸ ç« èŠ‚å†™ä½œ Prompt ä¸­çš„é…ç½®æ®µ")
            st.markdown(
                "ä»¥ä¸‹æ˜¯ `call_deepseek_write_chapter()` å‘é€ç»™ AI çš„ "
                "**å†™ä½œæŒ‡å¯¼è¿½åŠ æ®µ**ï¼ˆé™„åŠ åœ¨ system prompt æœ«å°¾ï¼‰ï¼š"
            )

            _sections_n = 6  # å‡è®¾ 6 ä¸ªç« èŠ‚ç”¨äºæ¼”ç¤º
            _wps = _wcount // max(_sections_n, 1)
            writing_prompt_segment = (
                f"7. ä½¿ç”¨{_lang}æ’°å†™\n"
                f"8. å†™ä½œæ°´å¹³è¦æ±‚ï¼š{_academic}{_level}çº§åˆ«\n"
                f"9. æœ¬ç« èŠ‚ç›®æ ‡å­—æ•°çº¦ {_wps} å­—\n"
                f"   (æ€»å­—æ•° {_wcount} Ã· å‡è®¾ {_sections_n} ç«  = {_wps} å­—/ç« )"
            )
            st.code(writing_prompt_segment, language="text")

            st.markdown("---")
            st.caption(
                "ğŸ’¡ æç¤ºï¼šæ­¤é¢æ¿ä»…å¼€å‘é˜¶æ®µæ˜¾ç¤ºã€‚"
                "åœ¨ä¾§è¾¹æ åº•éƒ¨å¯åˆ‡æ¢è°ƒè¯•æ¨¡å¼ã€‚"
                "å‘å¸ƒå‰åœ¨ sidebar.py å’Œ views.py ä¸­åˆ é™¤ debug_mode ç›¸å…³ä»£ç å³å¯ã€‚"
            )


# =====================================================================
# Step 1: å¤§çº²å¯¹æ¯”ä¸é€‰æ‹© (å¯¹æŠ—å¼ Cherry-pick)
# =====================================================================

def view_outline_review():
    """åŒç‰ˆæœ¬å¤§çº²å¯¹æ¯”ï¼Œç”¨æˆ·é€è¦ç‚¹ cherry-pick åˆå¹¶ã€‚"""

    st.header("ğŸ“‹ ç¬¬äºŒæ­¥ï¼šå¤§çº²å¯¹æ¯”ä¸é€‰æ‹©")
    st.markdown(
        "AI åŸºäºç›¸åŒçš„ç« èŠ‚æ¡†æ¶ç”Ÿæˆäº†ä¸¤ä»½é£æ ¼ä¸åŒçš„å¤§çº²ã€‚"
        "è¯·åœ¨æ¯ä¸ªç« èŠ‚ä¸­ **å‹¾é€‰æ‚¨å–œæ¬¢çš„è¦ç‚¹**ï¼Œè‡ªç”±æ··æ­ç»„åˆã€‚"
    )

    variant_a = st.session_state.get("outline_variant_a", {})
    variant_b = st.session_state.get("outline_variant_b", {})
    skeleton = st.session_state.get("outline_skeleton", {})

    if not variant_a or not variant_b:
        st.warning("âš ï¸ æœªæ‰¾åˆ°åŒç‰ˆæœ¬å¤§çº²æ•°æ®ï¼Œè¯·è¿”å›ä¸Šä¸€æ­¥é‡æ–°ç”Ÿæˆã€‚")
        if st.button("â¬…ï¸ è¿”å›é‡æ–°ä¸Šä¼ "):
            st.session_state["current_step"] = 0
            st.rerun()
        return

    sections_a = variant_a.get("sections", [])
    sections_b = variant_b.get("sections", [])
    title = skeleton.get("title", variant_a.get("title", "æœªå‘½åè®ºæ–‡"))

    st.markdown(f"### ğŸ“– {title}")

    # åˆå§‹åŒ– cherry_picks
    if not st.session_state.get("cherry_picks"):
        cherry_picks = {}
        for idx in range(max(len(sections_a), len(sections_b))):
            pts_a = sections_a[idx].get("points", []) if idx < len(sections_a) else []
            pts_b = sections_b[idx].get("points", []) if idx < len(sections_b) else []
            cherry_picks[str(idx)] = {
                "a": [False] * len(pts_a),
                "b": [False] * len(pts_b),
            }
        st.session_state["cherry_picks"] = cherry_picks

    cherry_picks = st.session_state["cherry_picks"]

    st.divider()

    # === é€ç« èŠ‚å¯¹æ¯” ===
    num_sections = max(len(sections_a), len(sections_b))
    for idx in range(num_sections):
        sec_a = sections_a[idx] if idx < len(sections_a) else {}
        sec_b = sections_b[idx] if idx < len(sections_b) else {}

        heading = sec_a.get("heading", sec_b.get("heading", f"ç¬¬ {idx + 1} ç« "))
        points_a = sec_a.get("points", [])
        points_b = sec_b.get("points", [])

        # ç¡®ä¿ cherry_picks ç»“æ„å­˜åœ¨
        if str(idx) not in cherry_picks:
            cherry_picks[str(idx)] = {
                "a": [False] * len(points_a),
                "b": [False] * len(points_b),
            }

        st.subheader(f"ğŸ“Œ {heading}")
        col_a, col_b = st.columns(2)

        with col_a:
            st.markdown("ğŸ…°ï¸ **ç‰ˆæœ¬ A** â€” ä¸¥è°¨å­¦æœ¯")
            for pi, point in enumerate(points_a):
                checked = cherry_picks[str(idx)]["a"][pi] if pi < len(cherry_picks[str(idx)]["a"]) else False
                val = st.checkbox(
                    point,
                    value=checked,
                    key=f"cp_a_{idx}_{pi}",
                )
                # åŒæ­¥åˆ° cherry_picks
                while len(cherry_picks[str(idx)]["a"]) <= pi:
                    cherry_picks[str(idx)]["a"].append(False)
                cherry_picks[str(idx)]["a"][pi] = val

        with col_b:
            st.markdown("ğŸ…±ï¸ **ç‰ˆæœ¬ B** â€” åˆ›æ–°å‘æ•£")
            for pi, point in enumerate(points_b):
                checked = cherry_picks[str(idx)]["b"][pi] if pi < len(cherry_picks[str(idx)]["b"]) else False
                val = st.checkbox(
                    point,
                    value=checked,
                    key=f"cp_b_{idx}_{pi}",
                )
                while len(cherry_picks[str(idx)]["b"]) <= pi:
                    cherry_picks[str(idx)]["b"].append(False)
                cherry_picks[str(idx)]["b"][pi] = val

        # æ˜¾ç¤ºå·²é€‰è¦ç‚¹æ‘˜è¦
        selected = []
        for pi, point in enumerate(points_a):
            if pi < len(cherry_picks[str(idx)]["a"]) and cherry_picks[str(idx)]["a"][pi]:
                selected.append(f"A-{pi+1}")
        for pi, point in enumerate(points_b):
            if pi < len(cherry_picks[str(idx)]["b"]) and cherry_picks[str(idx)]["b"][pi]:
                selected.append(f"B-{pi+1}")
        st.caption(f"âœ… å·²é€‰: {', '.join(selected) if selected else '(æ— )'}")

        st.divider()

    # === åˆå¹¶é¢„è§ˆ ===
    with st.expander("ğŸ‘ï¸ åˆå¹¶å¤§çº²é¢„è§ˆ", expanded=False):
        merged = _build_merged_outline(sections_a, sections_b, cherry_picks, title)
        for sec in merged.get("sections", []):
            st.markdown(f"**{sec.get('heading', '')}**")
            for pt in sec.get("points", []):
                st.markdown(f"  - {pt}")

    # === æ“ä½œæŒ‰é’® ===
    st.divider()
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("â¬…ï¸ è¿”å›é‡æ–°ä¸Šä¼ ", use_container_width=True):
            st.session_state["current_step"] = 0
            st.rerun()
    with col2:
        if st.button("ğŸ”„ é‡æ–°ç”Ÿæˆå¤§çº²", use_container_width=True):
            st.session_state["current_step"] = 0
            st.session_state["phase1_completed"] = False
            st.rerun()
    with col3:
        confirm_btn = st.button(
            "âœ… ç¡®è®¤åˆå¹¶å¤§çº² â†’ å®¡é˜…",
            type="primary",
            use_container_width=True,
        )

    if confirm_btn:
        merged = _build_merged_outline(sections_a, sections_b, cherry_picks, title)
        st.session_state["outline"] = merged

        # è°ƒç”¨ review_graph å®¡é˜…åˆå¹¶åçš„å¤§çº²
        try:
            with st.spinner("ğŸ§ AI æ­£åœ¨å®¡é˜…åˆå¹¶åçš„å¤§çº²..."):
                from backend.workflows import review_graph

                review_state = {
                    "outline": merged,
                    # å¡«å……å¿…è¦çš„é»˜è®¤å€¼ä»¥æ»¡è¶³ PaperState
                    "pdf_content": st.session_state.get("pdf_content", ""),
                    "user_intent": st.session_state.get("user_intent", ""),
                    "review_feedback": "",
                }
                final = {}
                for event in review_graph.stream(review_state):
                    if "review_outline" in event:
                        final.update(event["review_outline"])

                st.session_state["review_feedback"] = final.get(
                    "review_feedback", ""
                )

            st.session_state["current_step"] = 2
            st.rerun()

        except Exception as e:
            st.error(f"âŒ å®¡é˜…å¤±è´¥: {e}")

    # === å®¡é˜…æ„è§æ˜¾ç¤ºï¼ˆå¦‚æœå·²æœ‰ï¼‰ ===
    review_feedback = st.session_state.get("review_feedback", "")
    if review_feedback:
        st.divider()
        st.subheader("ğŸ“ AI å®¡é˜…æ„è§")
        st.markdown(review_feedback)


def _build_merged_outline(
    sections_a: list,
    sections_b: list,
    cherry_picks: dict,
    title: str,
) -> dict:
    """æ ¹æ® cherry_picks åˆå¹¶ä¸¤ä¸ªå˜ä½“çš„è¦ç‚¹ä¸ºä¸€ä»½å¤§çº²ã€‚"""
    merged_sections = []
    num_sections = max(len(sections_a), len(sections_b))

    for idx in range(num_sections):
        sec_a = sections_a[idx] if idx < len(sections_a) else {}
        sec_b = sections_b[idx] if idx < len(sections_b) else {}

        heading = sec_a.get("heading", sec_b.get("heading", f"ç¬¬ {idx + 1} ç« "))
        points_a = sec_a.get("points", [])
        points_b = sec_b.get("points", [])

        picks = cherry_picks.get(str(idx), {"a": [], "b": []})
        merged_points = []

        for pi, point in enumerate(points_a):
            if pi < len(picks.get("a", [])) and picks["a"][pi]:
                merged_points.append(point)

        for pi, point in enumerate(points_b):
            if pi < len(picks.get("b", [])) and picks["b"][pi]:
                merged_points.append(point)

        merged_sections.append({
            "heading": heading,
            "points": merged_points,
        })

    return {"title": title, "sections": merged_sections}


# =====================================================================
# Step 2: å¤§çº²ç¼–è¾‘å™¨ (äººæœºååŒ)
# =====================================================================

def view_outline_editor():
    """ç”¨æˆ·ç¼–è¾‘å¤§çº² JSONï¼Œç¡®è®¤åè§¦å‘ Phase 2 å†™ä½œã€‚"""

    st.header("âœï¸ ç¬¬ä¸‰æ­¥ï¼šç¼–è¾‘å¤§çº²")
    st.markdown(
        "æ‚¨å¯ä»¥ç›´æ¥ä¿®æ”¹ä¸‹æ–¹çš„ JSON å¤§çº²å†…å®¹ï¼Œ"
        "è°ƒæ•´ç« èŠ‚ç»“æ„ã€æ ‡é¢˜å’Œè¦ç‚¹ã€‚ç¡®è®¤åç‚¹å‡»æŒ‰é’®å¼€å§‹æ’°å†™æ­£æ–‡ã€‚"
    )

    outline = st.session_state.get("outline", {})

    # === JSON ç¼–è¾‘åŒºåŸŸ ===
    outline_json_str = json.dumps(outline, ensure_ascii=False, indent=2)

    edited_json = st.text_area(
        "ğŸ“ ç¼–è¾‘å¤§çº² (JSON æ ¼å¼)",
        value=outline_json_str,
        height=500,
        help="è¯·ä¿æŒ JSON æ ¼å¼æ­£ç¡®ï¼Œä¿®æ”¹ titleã€sectionsã€points ç­‰å­—æ®µ",
    )

    # === JSON æ ¼å¼ + ç»“æ„éªŒè¯ ===
    json_valid = True
    parsed_outline = outline
    try:
        parsed_outline = json.loads(edited_json)

        # --- ç»“æ„æ ¡éªŒ ---
        schema_errors = []
        if not isinstance(parsed_outline.get("title"), str) or not parsed_outline["title"].strip():
            schema_errors.append("ç¼ºå°‘ `title` å­—æ®µæˆ–ä¸ºç©º")
        sections = parsed_outline.get("sections")
        if not isinstance(sections, list) or len(sections) == 0:
            schema_errors.append("ç¼ºå°‘ `sections` å­—æ®µæˆ–ä¸ºç©ºåˆ—è¡¨")
        else:
            for i, sec in enumerate(sections):
                if not isinstance(sec.get("heading"), str) or not sec["heading"].strip():
                    schema_errors.append(f"ç¬¬ {i+1} ä¸ªç« èŠ‚ç¼ºå°‘ `heading`")
                if not isinstance(sec.get("points"), list):
                    schema_errors.append(f"ç¬¬ {i+1} ä¸ªç« èŠ‚ç¼ºå°‘ `points` åˆ—è¡¨")

        if schema_errors:
            st.error("âŒ å¤§çº²ç»“æ„ä¸å®Œæ•´ï¼š\n- " + "\n- ".join(schema_errors))
            json_valid = False
        else:
            st.success("âœ… JSON æ ¼å¼ä¸ç»“æ„æ ¡éªŒé€šè¿‡")

        # å¿«é€Ÿé¢„è§ˆ
        with st.expander("ğŸ‘ï¸ é¢„è§ˆç¼–è¾‘åçš„å¤§çº²"):
            title = parsed_outline.get("title", "æœªå‘½å")
            st.markdown(f"**æ ‡é¢˜**: {title}")
            for sec in parsed_outline.get("sections", []):
                st.markdown(f"- **{sec.get('heading', '')}**: "
                            f"{', '.join(sec.get('points', []))}")

    except json.JSONDecodeError as e:
        st.error(f"âŒ JSON æ ¼å¼é”™è¯¯: {e}")
        json_valid = False

    st.divider()

    # === æ“ä½œæŒ‰é’® ===
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("â¬…ï¸ è¿”å›å®¡é˜…", use_container_width=True):
            st.session_state["current_step"] = 1
            st.rerun()
    with col2:
        if st.button("ğŸ”„ é‡ç½®ä¸ºåŸå§‹å¤§çº²", use_container_width=True):
            st.rerun()  # text_area ä¼šæ¢å¤åˆ° session_state çš„å€¼
    with col3:
        start_writing = st.button(
            "ğŸš€ å¼€å§‹æ’°å†™æ­£æ–‡ (Phase 2)",
            type="primary",
            use_container_width=True,
            disabled=(not json_valid),
        )

    if start_writing and json_valid:
        # ä¿å­˜ç¼–è¾‘åçš„å¤§çº²
        st.session_state["outline"] = parsed_outline
        st.session_state["current_step"] = 3
        st.rerun()


# =====================================================================
# Step 3: å†™ä½œè¿›åº¦
# =====================================================================

def view_writing_progress():
    """Phase 2 æ‰§è¡Œï¼šåˆ†ç« èŠ‚å†™ä½œ + ç¼–è¯‘ Wordã€‚"""

    st.header("ğŸ“ ç¬¬å››æ­¥ï¼šæ­£æ–‡å†™ä½œ")

    outline = st.session_state.get("outline", {})
    sections = outline.get("sections", [])

    # å¦‚æœå°šæœªå¼€å§‹å†™ä½œï¼Œç«‹å³æ‰§è¡Œ
    if not st.session_state.get("phase2_completed", False):
        st.markdown(
            f"AI æ­£åœ¨æ ¹æ®æ‚¨ç¡®è®¤çš„å¤§çº²æ’°å†™æ­£æ–‡"
            f"ï¼ˆå…± {len(sections)} ä¸ªç« èŠ‚ï¼‰..."
        )

        # æ„å»º Phase 2 åˆå§‹çŠ¶æ€ï¼ˆåŒ…å«è®ºæ–‡é…ç½®ï¼‰
        phase2_state = {
            "paper_subject": st.session_state.get("paper_subject", ""),
            "paper_title": st.session_state.get("paper_title", ""),
            "paper_language": st.session_state.get("paper_language", "ä¸­æ–‡"),
            "academic_type": st.session_state.get("academic_type", "æœ¬ç§‘"),
            "paper_level": st.session_state.get("paper_level", "åˆçº§"),
            "paper_type": st.session_state.get("paper_type", "æ¯•ä¸šè®ºæ–‡"),
            "target_word_count": st.session_state.get("target_word_count", 8000),
            "keywords_cn": st.session_state.get("keywords_cn", []),
            "keywords_en": st.session_state.get("keywords_en", []),
            "pdf_content": st.session_state.get("pdf_content", ""),
            "is_scanned": st.session_state.get("is_scanned", False),
            "images_data": st.session_state.get("images_data", []),
            "user_intent": st.session_state.get("user_intent", ""),
            "outline": outline,
            "review_feedback": st.session_state.get("review_feedback", ""),
            "sections_content": {},
            "final_doc_path": "",
        }

        try:
            with st.spinner("ğŸ”„ AI æ­£åœ¨æ’°å†™è®ºæ–‡..."):
                progress_bar = st.progress(0, text="æ­£åœ¨æ’°å†™ç« èŠ‚...")

                final_state = {}
                step_count = 0
                total_steps = 2  # write_chapter, compile_word

                for event in writing_graph.stream(phase2_state):
                    step_count += 1
                    progress = min(step_count / total_steps, 1.0)

                    if "write_chapter" in event:
                        written = len(
                            event["write_chapter"].get("sections_content", {})
                        )
                        progress_bar.progress(
                            progress,
                            text=f"âœ… ç« èŠ‚å†™ä½œå®Œæˆ ({written}/{len(sections)} ç« )ï¼Œ"
                                 f"æ­£åœ¨ç¼–è¯‘ Word..."
                        )
                        final_state.update(event["write_chapter"])

                    elif "compile_word" in event:
                        progress_bar.progress(progress, text="âœ… Word æ–‡æ¡£ç¼–è¯‘å®Œæˆï¼")
                        final_state.update(event["compile_word"])

                progress_bar.progress(1.0, text="ğŸ‰ Phase 2 å…¨éƒ¨å®Œæˆï¼")

            # ä¿å­˜ç»“æœ
            if final_state:
                st.session_state["sections_content"] = final_state.get(
                    "sections_content", {}
                )
                st.session_state["final_doc_path"] = final_state.get(
                    "final_doc_path", ""
                )
                st.session_state["phase2_completed"] = True
                st.rerun()

        except Exception as e:
            error_msg = str(e)
            if "402" in error_msg or "Insufficient Balance" in error_msg:
                st.error(
                    "âŒ **API ä½™é¢ä¸è¶³**\n\n"
                    "æ‚¨çš„ DeepSeek API è´¦æˆ·ä½™é¢ä¸è¶³ï¼Œè¯·å‰å¾€ "
                    "[DeepSeek æ§åˆ¶å°](https://platform.deepseek.com/) å……å€¼åé‡è¯•ã€‚"
                )
            elif "401" in error_msg or "Unauthorized" in error_msg:
                st.error(
                    "âŒ **API Key æ— æ•ˆ**\n\n"
                    "è¯·æ£€æŸ¥ `.env` æ–‡ä»¶ä¸­çš„ `DEEPSEEK_API_KEY` æ˜¯å¦æ­£ç¡®ã€‚"
                )
            else:
                st.error(f"âŒ **AI å¤„ç†å‡ºé”™**: {error_msg}")
            st.info("ğŸ’¡ è¯·è§£å†³ä¸Šè¿°é—®é¢˜åï¼Œè¿”å›ç¼–è¾‘å¤§çº²é¡µé¢é‡è¯•ã€‚")

    else:
        # å†™ä½œå·²å®Œæˆï¼Œæ˜¾ç¤ºç« èŠ‚å†…å®¹
        st.success("âœ… å…¨éƒ¨ç« èŠ‚å†™ä½œå®Œæˆï¼")
        sections_content = st.session_state.get("sections_content", {})

        for section in sections:
            heading = section.get("heading", "")
            content = sections_content.get(heading, "ï¼ˆæœªç”Ÿæˆï¼‰")
            with st.expander(f"ğŸ“– {heading}", expanded=False):
                st.markdown(content)

        st.divider()

        col1, col2 = st.columns(2)
        with col1:
            if st.button("â¬…ï¸ è¿”å›ç¼–è¾‘å¤§çº²", use_container_width=True):
                st.session_state["phase2_completed"] = False
                st.session_state["current_step"] = 2
                st.rerun()
        with col2:
            if st.button(
                "ğŸ“¥ æŸ¥çœ‹ç»“æœä¸ä¸‹è½½",
                type="primary",
                use_container_width=True,
            ):
                st.session_state["current_step"] = 4
                st.rerun()


# =====================================================================
# Step 4: æœ€ç»ˆç»“æœå±•ç¤º
# =====================================================================

def view_results():
    """å±•ç¤ºæœ€ç»ˆç»“æœï¼šè®ºæ–‡å†…å®¹ + Word ä¸‹è½½ã€‚"""

    st.header("ğŸ‰ ç¬¬äº”æ­¥ï¼šç»“æœæ€»è§ˆ")

    outline = st.session_state.get("outline", {})
    sections_content = st.session_state.get("sections_content", {})
    images_data = st.session_state.get("images_data", [])
    final_doc_path = st.session_state.get("final_doc_path", "")

    # === è®ºæ–‡æ ‡é¢˜ ===
    st.markdown(f"## ğŸ“– {outline.get('title', 'æœªå‘½åè®ºæ–‡')}")

    # === ç»Ÿè®¡ä¿¡æ¯ ===
    total_chars = sum(len(v) for v in sections_content.values())
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ğŸ“Š æ€»ç« èŠ‚æ•°", len(sections_content))
    with col2:
        st.metric("ğŸ“ æ€»å­—æ•°", f"{total_chars:,}")
    with col3:
        st.metric("ğŸ–¼ï¸ å›¾ç‰‡æ•°", len(images_data))

    st.divider()

    # === å…¨æ–‡é¢„è§ˆ ===
    st.subheader("ğŸ“„ å…¨æ–‡é¢„è§ˆ")
    for section in outline.get("sections", []):
        heading = section.get("heading", "")
        content = sections_content.get(heading, "")
        if content:
            with st.expander(f"ğŸ“Œ {heading}", expanded=False):
                st.markdown(content)

    st.divider()

    # === å¯¼å‡ºåŒºåŸŸ ===
    st.subheader("ğŸ“¥ å¯¼å‡ºä¸‹è½½")
    col1, col2, col3 = st.columns(3)

    with col1:
        # ä¸‹è½½å¤§çº²
        if outline:
            st.download_button(
                label="ğŸ“‹ ä¸‹è½½å¤§çº² (JSON)",
                data=json.dumps(outline, ensure_ascii=False, indent=2),
                file_name="paper_outline.json",
                mime="application/json",
                use_container_width=True,
            )

    with col2:
        # ä¸‹è½½ Word æ–‡æ¡£
        if final_doc_path and os.path.exists(final_doc_path):
            with open(final_doc_path, "rb") as f:
                st.download_button(
                    label="ğŸ“„ ä¸‹è½½è®ºæ–‡ (Word)",
                    data=f.read(),
                    file_name="paper_output.docx",
                    mime=(
                        "application/vnd.openxmlformats-officedocument"
                        ".wordprocessingml.document"
                    ),
                    use_container_width=True,
                )
        else:
            st.button(
                "ğŸ“„ Word æ–‡ä»¶ä¸å¯ç”¨",
                disabled=True,
                use_container_width=True,
            )

    with col3:
        # ä¸‹è½½ Markdown å…¨æ–‡
        full_md = f"# {outline.get('title', 'æœªå‘½å')}\n\n"
        for section in outline.get("sections", []):
            heading = section.get("heading", "")
            content = sections_content.get(heading, "")
            full_md += f"\n{content}\n"

        st.download_button(
            label="ğŸ“ ä¸‹è½½å…¨æ–‡ (Markdown)",
            data=full_md,
            file_name="paper_full.md",
            mime="text/markdown",
            use_container_width=True,
        )

    st.divider()

    # === è¿”å›æŒ‰é’® ===
    if st.button("â¬…ï¸ è¿”å›å†™ä½œé¡µé¢", use_container_width=True):
        st.session_state["current_step"] = 3
        st.rerun()
